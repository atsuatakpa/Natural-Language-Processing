{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Assignment 4\n",
    "##### Atsu Atakpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK 3.3\n",
      "Beautiful Soup 4.6.0\n",
      "RE 2.2.1\n",
      "Requests 2.18.4\n",
      "Numpy:  1.14.3\n",
      "System version:  2.7.15 |Anaconda, Inc.| (default, May  1 2018, 18:37:09) [MSC v.1500 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries needed to complete assignment\n",
    "from __future__ import division, print_function\n",
    "from nltk import word_tokenize\n",
    "from urllib2 import Request, urlopen \n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import nltk; print(\"NLTK\",nltk.__version__)\n",
    "import bs4; print(\"Beautiful Soup\",bs4.__version__)\n",
    "import re; print(\"RE\",re.__version__)\n",
    "import requests; print(\"Requests\",requests.__version__)\n",
    "import numpy as np ; print(\"Numpy: \", np.__version__)\n",
    "import sys ;print(\"System version: \", sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tRun one of the part-of-speech (POS) taggers available in Python. \n",
    "    \n",
    "    a.\tFind the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.\n",
    "    \n",
    "    b.\tFind the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. \n",
    "    \n",
    "    Explain your conjecture as to why the tagger might have been less than perfect with this sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = word_tokenize(\"But some fans took a cynical view of the endeavor on Twitter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('But', 'CC'),\n",
       " ('some', 'DT'),\n",
       " ('fans', 'NNS'),\n",
       " ('took', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('cynical', 'JJ'),\n",
       " ('view', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('endeavor', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('Twitter', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "longSen=(\"But win, lose, or draw, the team will spend the first day of its bye week in the nation’s capital. Coaches and players will take a field trip Monday to the National Museum of African American History and Culture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But win, lose, or draw, the team will spend the first day of its bye week in the nation’s capital. Coaches and players will take a field trip Monday to the National Museum of African American History and Culture.\n"
     ]
    }
   ],
   "source": [
    "print(longSen) # Long sentense prior to tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "longSenTokenized = word_tokenize(longSen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['But', 'win', ',', 'lose', ',', 'or', 'draw', ',', 'the', 'team', 'will', 'spend', 'the', 'first', 'day', 'of', 'its', 'bye', 'week', 'in', 'the', 'nation\\xe2\\x80\\x99s', 'capital', '.', 'Coaches', 'and', 'players', 'will', 'take', 'a', 'field', 'trip', 'Monday', 'to', 'the', 'National', 'Museum', 'of', 'African', 'American', 'History', 'and', 'Culture', '.']\n"
     ]
    }
   ],
   "source": [
    "print (longSenTokenized) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('But', 'CC'),\n",
       " ('win', 'VB'),\n",
       " (',', ','),\n",
       " ('lose', 'VB'),\n",
       " (',', ','),\n",
       " ('or', 'CC'),\n",
       " ('draw', 'NN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('team', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('spend', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('first', 'JJ'),\n",
       " ('day', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('its', 'PRP$'),\n",
       " ('bye', 'NN'),\n",
       " ('week', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('nation\\xe2\\x80\\x99s', 'JJ'),\n",
       " ('capital', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Coaches', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('players', 'NNS'),\n",
       " ('will', 'MD'),\n",
       " ('take', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('field', 'NN'),\n",
       " ('trip', 'NN'),\n",
       " ('Monday', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('National', 'NNP'),\n",
       " ('Museum', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('African', 'JJ'),\n",
       " ('American', 'JJ'),\n",
       " ('History', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Culture', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(longSenTokenized) # long sentence with tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortSen = (\"And Jesus wept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And Jesus wept\n"
     ]
    }
   ],
   "source": [
    "print (shortSen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortSenTokenized = word_tokenize(shortSen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['And', 'Jesus', 'wept']\n"
     ]
    }
   ],
   "source": [
    "print (shortSenTokenized) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'), ('Jesus', 'NNP'), ('wept', 'VBD')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(shortSenTokenized) # long sentence with tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', u'CONJ'), ('Jesus', u'NOUN'), ('wept', u'VERB')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(shortSenTokenized, tagset = 'universal') # long sentence with tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Result\n",
    "The tagger was able to correctly tag the short sentence. \"Wept\" was correctly tagged as it was describing what Jesus did.\n",
    "I both cases, the tagger was able to correctly tagg the short and long sentences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a different POS tagger in Python. Process the same two sentences from question 1.<br>\n",
    "a.\tDoes it produce the same or different output? <br>\n",
    "b.\tExplain any differences as best you can.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employing Pattern POS Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'And', u'CC'), (u'Jesus', u'NNP-PERS'), (u'wept', u'VBD')]\n"
     ]
    }
   ],
   "source": [
    "from pattern.en import tag\n",
    "tagged_sent = tag(shortSen)\n",
    "print (tagged_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'But', u'CC'), (u'win', u'MD'), (u',', u','), (u'lose', u'VBP'), (u',', u','), (u'or', u'CC'), (u'draw', u'JJ'), (u',', u','), (u'the', u'DT'), (u'team', u'NN'), (u'will', u'MD'), (u'spend', u'VB'), (u'the', u'DT'), (u'first', u'JJ'), (u'day', u'NN'), (u'of', u'IN'), (u'its', u'PRP$'), (u'bye', u'VB'), (u'week', u'NN'), (u'in', u'IN'), (u'the', u'DT'), (u'nation\\u2019s', u'JJ'), (u'capital', u'NN'), (u'.', u'.'), (u'Coaches', u'NNS'), (u'and', u'CC'), (u'players', u'NNS'), (u'will', u'MD'), (u'take', u'VB'), (u'a', u'DT'), (u'field', u'NN'), (u'trip', u'NN'), (u'Monday', u'NNP'), (u'to', u'TO'), (u'the', u'DT'), (u'National', u'NNP'), (u'Museum', u'NNP'), (u'of', u'IN'), (u'African', u'NNP'), (u'American', u'NNP'), (u'History', u'NN'), (u'and', u'CC'), (u'Culture', u'NNP'), (u'.', u'.')]\n"
     ]
    }
   ],
   "source": [
    "tagged_Long_sent2 = tag(longSen)\n",
    "print (tagged_Long_sent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result\n",
    "* Both taggers did a great job of tagging the sentences. In the case of the short sentence, both taggers were able to tag them the same.\n",
    "* In the case of the long sentence, both the NLTK and Pattern taggers did a great job but there were a couple words that were not tagged the same. An example is the word \"American\". Pattern tagged it as an NNP(noun proper singular) and NLTK tagged it as JJ(adjective). Not sure why that was the case but there were a couple of other words that both taggers tagged differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a news article from this week’s news, find a random sentence of at least 10 words. <br>\n",
    "\n",
    "a.\tLooking at the Penn tag set, manually POS tag the sentence yourself.<br>\n",
    "b.\tNow run the same sentences through both taggers that you implemented for questions 1 and 2. Did either of the taggers produce the same results as you had created manually? <br>\n",
    "c.\tExplain any differences between the two taggers and your manual tagging as much as you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2 = (\"That's one of the most stunning results in AT&T Stadium history. The Cowboys winning isn't ridiculous. Jacksonville was only favored by a field goal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual tagging of Choosen sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "That's ( ADJECTIVE) one (NOUN) of the most stunning (ADJECTIVE) results in AT&T Stadium (NOUN) history. The Cowboys (NOUN) winning (VERB) isn't ridiculous (ADJECTIVE). Jacksonville (NOUN) was only (ADVERB) favored by a field goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsTokenized = word_tokenize(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['That', \"'s\", 'one', 'of', 'the', 'most', 'stunning', 'results', 'in', 'AT', '&', 'T', 'Stadium', 'history', '.', 'The', 'Cowboys', 'winning', 'is', \"n't\", 'ridiculous', '.', 'Jacksonville', 'was', 'only', 'favored', 'by', 'a', 'field', 'goal', '.']\n"
     ]
    }
   ],
   "source": [
    "print(newsTokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using NLTK to tagg sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('That', 'DT'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('most', 'RBS'),\n",
       " ('stunning', 'JJ'),\n",
       " ('results', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('AT', 'NNP'),\n",
       " ('&', 'CC'),\n",
       " ('T', 'NNP'),\n",
       " ('Stadium', 'NNP'),\n",
       " ('history', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('Cowboys', 'NNP'),\n",
       " ('winning', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " (\"n't\", 'RB'),\n",
       " ('ridiculous', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('Jacksonville', 'NNP'),\n",
       " ('was', 'VBD'),\n",
       " ('only', 'RB'),\n",
       " ('favored', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('field', 'NN'),\n",
       " ('goal', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(newsTokenized) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative Tagger (Pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'That', u'RB'), (u\"'s\", u'VBZ'), (u'one', u'CD'), (u'of', u'IN'), (u'the', u'DT'), (u'most', u'RBS'), (u'stunning', u'JJ'), (u'results', u'NNS'), (u'in', u'IN'), (u'AT&T', u'NNP-ORG'), (u'Stadium', u'NNP'), (u'history', u'NN'), (u'.', u'.'), (u'The', u'DT'), (u'Cowboys', u'NNS'), (u'winning', u'NN'), (u'is', u'VBZ'), (u\"n't\", u'RB'), (u'ridiculous', u'JJ'), (u'.', u'.'), (u'Jacksonville', u'NNP'), (u'was', u'VBD'), (u'only', u'RB'), (u'favored', u'VBN'), (u'by', u'IN'), (u'a', u'DT'), (u'field', u'NN'), (u'goal', u'NN'), (u'.', u'.')]\n"
     ]
    }
   ],
   "source": [
    "tagged_sent_news = tag(sentence2)\n",
    "print (tagged_sent_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result Differences\n",
    "* There wasn't much of a difference between the NLTK and Pattern taggers. However, the manual tagging wasn't as great as the one generated by NLTK and Pattern. An example is \"winning\" being tagged manually as a verb but both NLTK and Pattern tagged them as noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
