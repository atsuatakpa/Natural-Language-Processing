{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3 - Atsu Atakpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Compare your given name with your nickname (if you donâ€™t have a nickname, invent one for this assignment) by answering the following questions:\n",
    "\n",
    "a.\tWhat is the edit distance between your nickname and your given name? <br>\n",
    "b.\tWhat is the percentage string match between your nickname and your given name?\n",
    "\n",
    "Show your work for both calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Edit distance measures how near or far a word is from our input word.\n",
    "\n",
    "### My edit distance for my name \"Atsu\" and my nick name \"tsu-tsu\" is 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The edit distance for my name 'Atsu' to my nickname 'tsu-tsu' is: 4.00\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "#this calculates edit distance not levenstein edit distance\n",
    "word1=\"Atsu\"\n",
    "\n",
    "word2=\"tsu-tsu\"\n",
    "\n",
    "len_1=len(word1)\n",
    "\n",
    "len_2=len(word2)\n",
    "\n",
    "x =[[0]*(len_2+1) for _ in range(len_1+1)]#the matrix whose last element ->edit distance\n",
    "\n",
    "for i in range(0,len_1+1): #initialization of base case values\n",
    "\n",
    "    x[i][0]=i\n",
    "for j in range(0,len_2+1):\n",
    "\n",
    "    x[0][j]=j\n",
    "for i in range (1,len_1+1):\n",
    "\n",
    "    for j in range(1,len_2+1):\n",
    "\n",
    "        if word1[i-1]==word2[j-1]:\n",
    "            x[i][j] = x[i-1][j-1] \n",
    "\n",
    "        else :\n",
    "            x[i][j]= min(x[i][j-1],x[i-1][j],x[i-1][j-1])+1\n",
    "\n",
    "print (\"The edit distance for my name 'Atsu' to my nickname 'tsu-tsu' is: %.2f\" % x[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.\tWhat is the percentage string match between your nickname and your given name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First name length: 4.00\n",
      "Second name length: 7.00\n",
      "Sum of length: 11.00\n",
      "percentage string match between your nickname and your given name: 36.36\n"
     ]
    }
   ],
   "source": [
    "print(\"First name length: %.2f\" %len_1)\n",
    "print(\"Second name length: %.2f\" %len_2)\n",
    "print(\"Sum of length: %.2f\" %(len_1 + len_2))\n",
    "print(\"percentage string match between your nickname and your given name: %.2f\" %(x[i][j] / (len_1 + len_2) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My percentage string match between my nick name and given name is 36.36%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example of calculating the edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "def LD(s, t):\n",
    "    if s == \"\":\n",
    "        return len(t)\n",
    "    if t == \"\":\n",
    "        return len(s)\n",
    "    if s[-1] == t[-1]:\n",
    "        cost = 0\n",
    "    else:\n",
    "        cost = 1\n",
    "       \n",
    "    res = min([LD(s[:-1], t)+1,\n",
    "               LD(s, t[:-1])+1, \n",
    "               LD(s[:-1], t[:-1]) + cost])\n",
    "    return res\n",
    "print(LD(\"Atsu\", \"tsu-tsu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a friend (or family member or classmate) who you know has read a certain book. Without your friend knowing, copy the first two sentences of that book. <br> Now rewrite the words from those sentences, excluding stop words. <br> Now tell your friend to guess which book the words are from by reading them just that list of words.<br> Did you friend correctly guess the book on the first try?<br> What did he or she guess?<br> Explain why you think you friend either was or was not able to guess the book from hearing the list of words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "\n",
    "* The text is from the book \"The fox and the hound\" by Daniel P. Mannix\n",
    "\n",
    "My friend was able to correctly guess the book. One of the main reasons why she could guess the book was because it is a common book. She read it a couple of times when she was younger. However, the output of the words also gave it away. Output such as\n",
    "   'The',\n",
    "   'big',\n",
    "   'half-bred',\n",
    "   'bloodhound'\n",
    "Made it much easier for her. The guess wasn't instant but she got it. If this exercise was conducted on a book she has probably read only once, I'm not sure the outcome will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus =[\"The big half-bred bloodhound lay in his barrel kennel and dreamed he was a deer hunting. Of all the quarry he had ever trailed, deer was the hound's favorite, although it was usually strictly forbidden. He had been whipped, beaten with a club, and even hit in the flanks by bird shot from this crime; yet once, after an interminable journey to a faraway place, he had been allowed to track a deer.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The big half-bred bloodhound lay in his barrel kennel and dreamed he was a deer hunting. Of all the quarry he had ever trailed, deer was the hound's favorite, although it was usually strictly forbidden. He had been whipped, beaten with a club, and even hit in the flanks by bird shot from this crime; yet once, after an interminable journey to a faraway place, he had been allowed to track a deer.\"]\n"
     ]
    }
   ],
   "source": [
    "print corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    word_tokens = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "    return word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['The',\n",
      "   'big',\n",
      "   'half-bred',\n",
      "   'bloodhound',\n",
      "   'lay',\n",
      "   'in',\n",
      "   'his',\n",
      "   'barrel',\n",
      "   'kennel',\n",
      "   'and',\n",
      "   'dreamed',\n",
      "   'he',\n",
      "   'was',\n",
      "   'a',\n",
      "   'deer',\n",
      "   'hunting',\n",
      "   '.'],\n",
      "  ['Of',\n",
      "   'all',\n",
      "   'the',\n",
      "   'quarry',\n",
      "   'he',\n",
      "   'had',\n",
      "   'ever',\n",
      "   'trailed',\n",
      "   ',',\n",
      "   'deer',\n",
      "   'was',\n",
      "   'the',\n",
      "   'hound',\n",
      "   \"'s\",\n",
      "   'favorite',\n",
      "   ',',\n",
      "   'although',\n",
      "   'it',\n",
      "   'was',\n",
      "   'usually',\n",
      "   'strictly',\n",
      "   'forbidden',\n",
      "   '.'],\n",
      "  ['He',\n",
      "   'had',\n",
      "   'been',\n",
      "   'whipped',\n",
      "   ',',\n",
      "   'beaten',\n",
      "   'with',\n",
      "   'a',\n",
      "   'club',\n",
      "   ',',\n",
      "   'and',\n",
      "   'even',\n",
      "   'hit',\n",
      "   'in',\n",
      "   'the',\n",
      "   'flanks',\n",
      "   'by',\n",
      "   'bird',\n",
      "   'shot',\n",
      "   'from',\n",
      "   'this',\n",
      "   'crime',\n",
      "   ';',\n",
      "   'yet',\n",
      "   'once',\n",
      "   ',',\n",
      "   'after',\n",
      "   'an',\n",
      "   'interminable',\n",
      "   'journey',\n",
      "   'to',\n",
      "   'a',\n",
      "   'faraway',\n",
      "   'place',\n",
      "   ',',\n",
      "   'he',\n",
      "   'had',\n",
      "   'been',\n",
      "   'allowed',\n",
      "   'to',\n",
      "   'track',\n",
      "   'a',\n",
      "   'deer',\n",
      "   '.']]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "token_list = [tokenize_text(text) for text in corpus]\n",
    "pprint (token_list)\n",
    "print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_characters_after_tokenization(tokens):\n",
    "    pattern = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "    filtered_tokens = filter(None, [pattern.sub('', token) for token in tokens])\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['The', 'big', 'halfbred', 'bloodhound', 'lay', 'in', 'his', 'barrel', 'kennel', 'and', 'dreamed', 'he', 'was', 'a', 'deer', 'hunting'], ['Of', 'all', 'the', 'quarry', 'he', 'had', 'ever', 'trailed', 'deer', 'was', 'the', 'hound', 's', 'favorite', 'although', 'it', 'was', 'usually', 'strictly', 'forbidden'], ['He', 'had', 'been', 'whipped', 'beaten', 'with', 'a', 'club', 'and', 'even', 'hit', 'in', 'the', 'flanks', 'by', 'bird', 'shot', 'from', 'this', 'crime', 'yet', 'once', 'after', 'an', 'interminable', 'journey', 'to', 'a', 'faraway', 'place', 'he', 'had', 'been', 'allowed', 'to', 'track', 'a', 'deer']]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_list_1 =  [filter(None,[remove_characters_after_tokenization(tokens) \n",
    "                                for tokens in sentence_tokens]) \n",
    "                    for sentence_tokens in token_list]\n",
    "print filtered_list_1\n",
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_characters_before_tokenization(sentence,\n",
    "                                          keep_apostrophes=False):\n",
    "    sentence = sentence.strip()\n",
    "    if keep_apostrophes:\n",
    "        PATTERN = r'[?|$|&|*|%|@|(|)|~]'\n",
    "        filtered_sentence = re.sub(PATTERN, r'', sentence)\n",
    "    else:\n",
    "        PATTERN = r'[^a-zA-Z0-9 ]'\n",
    "        filtered_sentence = re.sub(PATTERN, r'', sentence)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The big halfbred bloodhound lay in his barrel kennel and dreamed he was a deer hunting Of all the quarry he had ever trailed deer was the hounds favorite although it was usually strictly forbidden He had been whipped beaten with a club and even hit in the flanks by bird shot from this crime yet once after an interminable journey to a faraway place he had been allowed to track a deer']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_list_2 = [remove_characters_before_tokenization(sentence) \n",
    "                    for sentence in corpus]    \n",
    "print filtered_list_2\n",
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The big half-bred bloodhound lay in his barrel kennel and dreamed he was a deer hunting. Of all the quarry he had ever trailed, deer was the hound's favorite, although it was usually strictly forbidden. He had been whipped, beaten with a club, and even hit in the flanks by bird shot from this crime; yet once, after an interminable journey to a faraway place, he had been allowed to track a deer.\"]\n"
     ]
    }
   ],
   "source": [
    "cleaned_corpus = [remove_characters_before_tokenization(sentence, keep_apostrophes=True) \n",
    "                  for sentence in corpus]\n",
    "print cleaned_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTRACTION_MAP = {\n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The big half-bred bloodhound lay in his barrel kennel and dreamed he was a deer hunting. Of all the quarry he had ever trailed, deer was the hound's favorite, although it was usually strictly forbidden. He had been whipped, beaten with a club, and even hit in the flanks by bird shot from this crime; yet once, after an interminable journey to a faraway place, he had been allowed to track a deer.\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from contractions import CONTRACTION_MAP\n",
    "\n",
    "def expand_contractions(sentence, contraction_mapping):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_sentence = contractions_pattern.sub(expand_match, sentence)\n",
    "    return expanded_sentence\n",
    "    \n",
    "expanded_corpus = [expand_contractions(sentence, CONTRACTION_MAP) \n",
    "                    for sentence in cleaned_corpus]    \n",
    "print expanded_corpus\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the big half-bred bloodhound lay in his barrel kennel and dreamed he was a deer hunting. of all the quarry he had ever trailed, deer was the hound's favorite, although it was usually strictly forbidden. he had been whipped, beaten with a club, and even hit in the flanks by bird shot from this crime; yet once, after an interminable journey to a faraway place, he had been allowed to track a deer.\n",
      "THE BIG HALF-BRED BLOODHOUND LAY IN HIS BARREL KENNEL AND DREAMED HE WAS A DEER HUNTING. OF ALL THE QUARRY HE HAD EVER TRAILED, DEER WAS THE HOUND'S FAVORITE, ALTHOUGH IT WAS USUALLY STRICTLY FORBIDDEN. HE HAD BEEN WHIPPED, BEATEN WITH A CLUB, AND EVEN HIT IN THE FLANKS BY BIRD SHOT FROM THIS CRIME; YET ONCE, AFTER AN INTERMINABLE JOURNEY TO A FARAWAY PLACE, HE HAD BEEN ALLOWED TO TRACK A DEER.\n"
     ]
    }
   ],
   "source": [
    "# case conversion    \n",
    "print corpus[0].lower()\n",
    "print corpus[0].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['The', 'big', 'half-bred', 'bloodhound', 'lay', 'barrel', 'kennel', 'dreamed', 'deer', 'hunting', '.'], ['Of', 'quarry', 'ever', 'trailed', ',', 'deer', 'hound', \"'s\", 'favorite', ',', 'although', 'usually', 'strictly', 'forbidden', '.'], ['He', 'whipped', ',', 'beaten', 'club', ',', 'even', 'hit', 'flanks', 'bird', 'shot', 'crime', ';', 'yet', ',', 'interminable', 'journey', 'faraway', 'place', ',', 'allowed', 'track', 'deer', '.']]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# removing stopwords\n",
    "def remove_stopwords(tokens):\n",
    "    stopword_list = nltk.corpus.stopwords.words('english')\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    return filtered_tokens\n",
    "    \n",
    "expanded_corpus_tokens = [tokenize_text(text)\n",
    "                          for text in expanded_corpus]    \n",
    "filtered_list_3 =  [[remove_stopwords(tokens) \n",
    "                        for tokens in sentence_tokens] \n",
    "                        for sentence_tokens in expanded_corpus_tokens]\n",
    "print filtered_list_3\n",
    "print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tRun one of the stemmers available in Python. Run the same two sentences from question 2 above through the stemmer and show the results. How many of the outputted stems are valid morphological roots of the corresponding words? Express this answer as a percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(filtered_list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'big', 'half-bred', 'bloodhound', 'lay', 'barrel', 'kennel', 'dreamed', 'deer', 'hunting', '.']\n"
     ]
    }
   ],
   "source": [
    "print filtered_list_3[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Of', 'quarry', 'ever', 'trailed', ',', 'deer', 'hound', \"'s\", 'favorite', ',', 'although', 'usually', 'strictly', 'forbidden', '.']\n"
     ]
    }
   ],
   "source": [
    "print filtered_list_3[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen1=((word.lower() for word in filtered_list_3[0][0] if word.isalpha())) # new dataframe that cleans up capitlizations, and aplha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "big\n",
      "bloodhound\n",
      "lay\n",
      "barrel\n",
      "kennel\n",
      "dream\n",
      "deer\n",
      "hunt\n"
     ]
    }
   ],
   "source": [
    "for w in sen1:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen2=((word.lower() for word in filtered_list_3[0][1] if word.isalpha())) # new dataframe that cleans up capitlizations, and aplha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x000000000A5CCB88>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object <genexpr> at 0x000000000A5CCB88>\n"
     ]
    }
   ],
   "source": [
    "print sen2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of\n",
      "quarri\n",
      "ever\n",
      "trail\n",
      "deer\n",
      "hound\n",
      "favorit\n",
      "although\n",
      "usual\n",
      "strictli\n",
      "forbidden\n"
     ]
    }
   ],
   "source": [
    "for w in sen2:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOURCE:https://stackoverflow.com/questions/2460177/edit-distance-in-python\n",
    "https://www.python-course.eu/levenshtein_distance.php\n",
    "https://stackoverflow.com/questions/2460177/edit-distance-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
